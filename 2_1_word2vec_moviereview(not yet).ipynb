{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./soy/')\n",
    "import soy\n",
    "\n",
    "\n",
    "TRAIN_COHESION = True\n",
    "TOKENIZE = True\n",
    "\n",
    "corpus_fname = './data/sample_naver_movie/merged_comments.txt'\n",
    "tokenized_corpus_fname = './data/sample_naver_movie/merged_comments_tokenized.txt'\n",
    "cohesion_fname = './data/sample_naver_movie/navermovie_cohesion'\n",
    "maxscore_fname = './data/sample_naver_movie/navermovie_maxscore.pkl'\n",
    "\n",
    "\n",
    "TRAIN_WORD2VEC = True\n",
    "word2vec_fname = './data/sample_naver_movie/movie_review_word2vec_model.pkl'\n",
    "\n",
    "\n",
    "TRAIN_DOC2VEC = True\n",
    "doc2vec_fname = './data/sample_naver_movie/movie_review_doc2vec_model.pkl'\n",
    "\n",
    "id2movie_fname = './data/sample_naver_movie/navermovie_info_idx2moviename.pkl'\n",
    "id2actor_fname = './data/sample_naver_movie/navermovie_info_idx2actorname.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('명불허전',\n",
       " '왠지 고사 피의중간고사보다 재미가없을듯해요 만약보게된다면실망할듯',\n",
       " '티아라 사랑해 ㅜ',\n",
       " '황정음 윤시윤 지붕킥 인연 김수로 티아라지연 공부의신 인연 너무너무재미있어요',\n",
       " '기대 완전')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text(fname):\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        docs = [doc.strip().split('\\t') for doc in f]\n",
    "    \n",
    "    idx, texts, scores = zip(*docs)\n",
    "    return idx, texts, scores\n",
    "\n",
    "idx, docs, scores = get_text(corpus_fname)\n",
    "docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280685"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from soy.nlp.extractors import CohesionProbability\n",
    "\n",
    "cohesion = CohesionProbability()\n",
    "\n",
    "if TRAIN_COHESION:\n",
    "    cohesion.train(docs)\n",
    "    cohesion.save(cohesion_fname)\n",
    "    \n",
    "    scores = cohesion.get_all_cohesion_probabilities()\n",
    "    scores = {word:s[0] for word, s in scores.items() if s[2] >= 10 and s[0] > 0.001}\n",
    "    with open(maxscore_fname, 'wb') as f:\n",
    "        pickle.dump(scores, f)\n",
    "        \n",
    "else:\n",
    "    cohesion.load(cohesion_fname)\n",
    "    with open(maxscore_fname, 'rb') as f:\n",
    "        scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명불허전\n",
      "['명불허전'] \n",
      "\n",
      "왠지 고사 피의중간고사보다 재미가없을듯해요 만약보게된다면실망할듯\n",
      "['왠지', '고사', '피의', '중간', '고사', '보다', '재미', '가', '없을', '듯해요', '만약', '보게', '된다', '면', '실망', '할듯'] \n",
      "\n",
      "티아라 사랑해 ㅜ\n",
      "['티아라', '사랑', '해', 'ㅜ'] \n",
      "\n",
      "tokenizing was done\n"
     ]
    }
   ],
   "source": [
    "from soy.nlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "tokenizer = MaxScoreTokenizer(scores=scores)\n",
    "\n",
    "for doc in docs[:3]:\n",
    "    print(doc)\n",
    "    print(tokenizer.tokenize(doc), '\\n')\n",
    "\n",
    "if TOKENIZE:\n",
    "    with open(tokenized_corpus_fname, 'w', encoding='utf-8') as f:\n",
    "        for idx_, text, score in zip(idx, docs, scores):\n",
    "            tokens = ' '.join(tokenizer.tokenize(text)).strip()\n",
    "            f.write('%s\\t%s\\t%s\\n' % (idx_, tokens, score))\n",
    "            \n",
    "    print('tokenizing was done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['명불허전']\n",
      "['왠지', '고사', '피의', '중간', '고사', '보다', '재미', '가', '없을', '듯해요', '만약', '보게', '된다', '면', '실망', '할듯']\n",
      "['티아라', '사랑', '해', 'ㅜ']\n",
      "['황정', '음', '윤시윤', '지붕킥', '인연', '김수', '로', '티아라', '지연', '공부', '의신', '인연', '너무', '너무', '재미', '있어', '요']\n",
      "['기대', '완전']\n",
      "['기대', '지연', '나온다']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "    \n",
    "class CommentWord2Vec:\n",
    "    \n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        if not os.path.isfile(fname):\n",
    "            print('File not found: %s' % fname)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        with open(self.fname, encoding='utf-8') as f:\n",
    "            for doc in f:\n",
    "                movie_idx, text, score = doc.split('\\t')\n",
    "                yield text.split()\n",
    "                \n",
    "                \n",
    "word2vec_corpus = CommentWord2Vec(tokenized_corpus_fname)\n",
    "\n",
    "for num_doc, doc in enumerate(word2vec_corpus):\n",
    "    if num_doc > 5: break\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim의 Word2Vec을 이용합니다. 미리 만들어둔 word2vec_corpus를 Word2Vec의 argument로 입력합니다. default parameters를 이용하여 Word2Vec을 학습힙니다. \n",
    "\n",
    "Word2Vec의 arguments 중에서 중요한 것들은 아래와 같습니다. \n",
    "\n",
    "- size: 단어의 임베딩 공간의 크기\n",
    "- alpha: learning rate\n",
    "- window: 한 단어의 좌/우의 문맥 크기\n",
    "- min_count: 모델이 학습할 단어의 최소 출현 빈도수\n",
    "- max_vocab_size: None이 아닌 숫자를 입력하면 빈도수 기준으로 상위 max_vocab_size 개수만큼의 단어만 학습\n",
    "- sg: 1이면 skipgram 이용\n",
    "- negative: negative sampling에서 negative sample의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CommentWord2Vec at 0x10e5c95c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "\n",
    "if TRAIN_WORD2VEC:\n",
    "    word2vec_model = Word2Vec(word2vec_corpus)\n",
    "    with open(word2vec_fname, 'wb') as f:\n",
    "        pickle.dump(word2vec_model, f)\n",
    "        \n",
    "else:\n",
    "    with open(word2vec_fname, 'rb') as f:\n",
    "        word2vec_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 Word2Vec모델의 .most_similar(단어, topn) 함수는 입력된 단어에 대하여 가장 비슷한 topn개의 다른 단어들과 유사도를 출력합니다. \n",
    "\n",
    "아래의 에제에서 '영화'와 가장 비슷한 단어는 '애니'이며, 유사도는 0.7270입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_WORD2VEC:\n",
    "    word2vec_model = Word2Vec(word2vec_corpus)\n",
    "    with open(word2vec_fname, 'wb') as f:\n",
    "        pickle.dump(word2vec_model, f)\n",
    "        \n",
    "else:\n",
    "    with open(word2vec_fname, 'rb') as f:\n",
    "        word2vec_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x10e5be320>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('작품', 0.6003116369247437),\n",
       " ('블록버스터', 0.5519367456436157),\n",
       " ('결과', 0.5387158393859863),\n",
       " ('장르', 0.5341578125953674),\n",
       " ('소재', 0.48169851303100586),\n",
       " ('나에게', 0.4721364378929138),\n",
       " ('시리즈', 0.46323785185813904),\n",
       " ('대작', 0.4631398916244507),\n",
       " ('건', 0.4575556516647339),\n",
       " ('주제', 0.4552241563796997)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(\"영화\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('성동일', 0.7917931079864502),\n",
       " ('임달화', 0.7671147584915161),\n",
       " ('송강호', 0.7656506896018982),\n",
       " ('김윤석', 0.7547394037246704),\n",
       " ('이민기', 0.746239423751831),\n",
       " ('조윤희', 0.730881929397583),\n",
       " ('한예리', 0.712838888168335),\n",
       " ('김해숙', 0.705826461315155),\n",
       " ('유해진', 0.700925350189209),\n",
       " ('전지현', 0.6980483531951904)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar('하정우', topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
