{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data Loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set and test set\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "newsgroups_test  = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "X_train = newsgroups_train.data\n",
    "Y_train = newsgroups_train.target\n",
    "X_test  = newsgroups_test.data\n",
    "Y_test  = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRry the SKywatch project in  Arizona.', 'The Vatican library recently made a tour of the US.\\n Can anyone help me in finding a FTP site where this collection is \\n available.', 'Hi there,\\n\\nI am here looking for some help.\\n\\nMy friend is a interior decor designer. He is from Thailand. He is\\ntrying to find some graphics software on PC. Any suggestion on which\\nsoftware to buy,where to buy and how much it costs ? He likes the most\\nsophisticated \\nsoftware(the more features it has,the better)']\n",
      "[2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0:3])\n",
    "print(Y_test[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare two vectorizers\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting vectorizers to the training set\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform X_train and X_test using 2 vectorizers\n",
    "# X_train_count = count_vectorizer.transform(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "# X_test_count  = count_vectorizer.transform(X_test)\n",
    "X_test_tfidf  = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dense vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix into dense matrix\n",
    "X_train = X_train_tfidf.toarray()\n",
    "X_test = X_test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training points:  2034\n",
      "Number of test points:  1353\n"
     ]
    }
   ],
   "source": [
    "num_train = Y_train.shape[0]\n",
    "num_test = Y_test.shape[0]\n",
    "\n",
    "print(\"Number of training points: \", num_train)\n",
    "print(\"Number of test points: \", num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X: 758\n"
     ]
    }
   ],
   "source": [
    "dim_X = X_train.shape[1]\n",
    "print(\"Dimension of X: %d\" % dim_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(Y_test)\n",
    "print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fitting classifiers with TF-IDF vectorizer with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Placeholder\n",
    "- Shape of the placeholder for inputs: [batch_size, dim_X]\n",
    "- Shape of the placeholder for outputs: [batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dim_X], name=\"Inputs\")\n",
    "Y = tf.placeholder(tf.int32, [None], name=\"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Build the model\n",
    "- with TF-Slim\n",
    "- https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(inputs, num_labels, hidden_sizes=[100, 100], scope='FCN'):\n",
    "    \"\"\"\n",
    "    [fully_connected] n개의 hidden layer를 갖는 feed-forward network 생성 (with TF-Slim)\n",
    "    \n",
    "    [Args]\n",
    "      - inputs: 입력 데이터를 위한 placeholder\n",
    "      - hidden_sizes: a list (은닉 노드 수를 원하는 층 수 만큼 기록한 리스트)\n",
    "      - Scope: default value (\"FCN\")\n",
    "    \"\"\"\n",
    "    # Inputs에서 1차원의 텐서들이 placeholder로 들어온다고 가정\n",
    "    input_dim = inputs.get_shape()[1]\n",
    "\n",
    "    # Number of hidden layers\n",
    "    num_hidden_layers = len(hidden_sizes)\n",
    "    \n",
    "    with slim.arg_scope([slim.fully_connected],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                        biases_initializer=tf.constant_initializer(0.0)):\n",
    "        net = inputs\n",
    "        for i in range(num_hidden_layers):\n",
    "            scope_name = 'fc' + str(i)\n",
    "            net = slim.fully_connected(inputs=net, num_outputs=hidden_sizes[i], scope=scope_name)\n",
    "        net = slim.fully_connected(inputs=net, num_outputs=num_labels, activation_fn=None, scope='logits')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fully_connected(inputs=X, num_labels=len(labels), hidden_sizes=[100, 100], scope='FCN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Predicting operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.nn.in_top_k(logits, Y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "NUM_EPOCHS = 40\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 결과를 저장할 리스트를 생성\n",
    "train_cost_list = []\n",
    "test_cost_list = []\n",
    "test_accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 epoch] training cost 0.8086\n",
      "[2 epoch] training cost 0.3784\n",
      "[3 epoch] training cost 0.2137\n",
      "[4 epoch] training cost 0.1946\n",
      "[5 epoch] training cost 0.1616\n",
      "[6 epoch] training cost 0.1125\n",
      "[7 epoch] training cost 0.0743\n",
      "[8 epoch] training cost 0.0686\n",
      "[9 epoch] training cost 0.0649\n",
      "[10 epoch] training cost 0.0741\n",
      "\t[10 epoch] test accuracy 0.6364\n",
      "[11 epoch] training cost 0.0556\n",
      "[12 epoch] training cost 0.0574\n",
      "[13 epoch] training cost 0.0455\n",
      "[14 epoch] training cost 0.0451\n",
      "[15 epoch] training cost 0.0439\n",
      "[16 epoch] training cost 0.0438\n",
      "[17 epoch] training cost 0.0438\n",
      "[18 epoch] training cost 0.0438\n",
      "[19 epoch] training cost 0.0438\n",
      "[20 epoch] training cost 0.0438\n",
      "\t[20 epoch] test accuracy 0.6563\n",
      "[21 epoch] training cost 0.0438\n",
      "[22 epoch] training cost 0.0438\n",
      "[23 epoch] training cost 0.0438\n",
      "[24 epoch] training cost 0.0438\n",
      "[25 epoch] training cost 0.0438\n",
      "[26 epoch] training cost 0.0438\n",
      "[27 epoch] training cost 0.0437\n",
      "[28 epoch] training cost 0.0437\n",
      "[29 epoch] training cost 0.0437\n",
      "[30 epoch] training cost 0.0437\n",
      "\t[30 epoch] test accuracy 0.6556\n",
      "[31 epoch] training cost 0.0437\n",
      "[32 epoch] training cost 0.0437\n",
      "[33 epoch] training cost 0.0437\n",
      "[34 epoch] training cost 0.0437\n",
      "[35 epoch] training cost 0.0437\n",
      "[36 epoch] training cost 0.0437\n",
      "[37 epoch] training cost 0.0436\n",
      "[38 epoch] training cost 0.0436\n",
      "[39 epoch] training cost 0.0436\n",
      "[40 epoch] training cost 0.0436\n",
      "\t[40 epoch] test accuracy 0.6571\n",
      "\n",
      "\n",
      "Test accuracy: 0.6571\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Variable initialization\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Indices for constructing batches\n",
    "    start_idx = range(0, num_train, BATCH_SIZE)\n",
    "    end_idx = range(BATCH_SIZE, num_train + 1, BATCH_SIZE)\n",
    "    \n",
    "    NUM_BATCHES = len(start_idx)\n",
    "    \n",
    "    for epoch in range(0,NUM_EPOCHS):\n",
    "\n",
    "        # Set \"train_cost\" as 0 before starting the epoch\n",
    "        train_cost = 0\n",
    "        \n",
    "        # Training phase\n",
    "        for start, end in zip(start_idx, end_idx):\n",
    "\n",
    "            # Construct the input batch\n",
    "            batch_xs = X_train[start:end]\n",
    "            batch_ys = Y_train[start:end]\n",
    "            \n",
    "            # Calculate cost\n",
    "            tmp_cost, _ = sess.run([cost, train_op], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            train_cost += tmp_cost\n",
    "        \n",
    "        train_cost = train_cost / NUM_BATCHES\n",
    "        train_cost_list.append(train_cost)\n",
    "        print(\"[{} epoch] training cost {:0.4f}\".format((epoch + 1), train_cost))\n",
    "        \n",
    "        # Validation phase\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            test_cost, test_accuracy = sess.run([cost, accuracy], feed_dict={X: X_test, Y: Y_test})\n",
    "            test_cost_list.append(test_cost)\n",
    "            test_accuracy_list.append(test_accuracy)\n",
    "            print(\"\\t[{} epoch] test accuracy {:0.4f}\".format((epoch + 1), test_accuracy))\n",
    "            \n",
    "    # Test phase\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: X_test, Y: Y_test})\n",
    "    print(\"\\n\")\n",
    "    print(\"Test accuracy: {:0.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
