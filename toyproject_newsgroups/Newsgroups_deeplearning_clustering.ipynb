{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdditiveGaussianNoiseAutoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function=tf.nn.softplus, optimizer=tf.train.AdamOptimizer(),\n",
    "                 scale=0.1):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)\n",
    "        self.training_scale = scale\n",
    "\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "\n",
    "        # model\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        self.corrupted = self.x + scale * tf.random_normal((n_input,))\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.corrupted, self.weights['w1']), self.weights['b1']))\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n",
    "\n",
    "        # cost\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n",
    "        return all_weights\n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict = {self.x: X,\n",
    "                                                                            self.scale: self.training_scale\n",
    "                                                                            })\n",
    "        return cost\n",
    "\n",
    "    def calc_total_cost(self, X):\n",
    "        return self.sess.run(self.cost, feed_dict = {self.x: X,\n",
    "                                                     self.scale: self.training_scale\n",
    "                                                     })\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden, feed_dict = {self.x: X,\n",
    "                                                       self.scale: self.training_scale\n",
    "                                                       })\n",
    "\n",
    "    def generate(self, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.x: X,\n",
    "                                                               self.scale: self.training_scale\n",
    "                                                               })\n",
    "    def corrupt(self, X):\n",
    "        return self.sess.run(self.corrupted, fedd_dict={self.x:X, self.scale: self.training_scale})\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "\n",
    "    def getBiases(self):\n",
    "        return self.sess.run(self.weights['b1'])\n",
    "\n",
    "\n",
    "class MaskingNoiseAutoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus, optimizer = tf.train.AdamOptimizer(),\n",
    "                 dropout_probability = 0.95, tied_weights=False):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.dropout_probability = dropout_probability\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        self.tied_weights = tied_weights\n",
    "\n",
    "        network_weights = self._initialize_weights(tied=self.tied_weights)\n",
    "        self.weights = network_weights\n",
    "\n",
    "        # model\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        self.corrupted = tf.nn.dropout(self.x, self.keep_prob)\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.corrupted, self.weights['w1']), self.weights['b1']))\n",
    "        self.reconstruction = self.transfer(tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2']))\n",
    "\n",
    "        # cost\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    # def _initialize_weights(self, tied):\n",
    "    #     all_weights = dict()\n",
    "    #     all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n",
    "    #         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n",
    "    #     if tied == True:\n",
    "    #         all_weights['w2'] = tf.transpose(all_weights['w1'])\n",
    "    #     else:\n",
    "    #         all_weights['w2'] = = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n",
    "    #     all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n",
    "    #     return all_weights\n",
    "\n",
    "    def _initialize_weights(self, tied):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.get_variable('w1', shape=[self.n_input, self.n_hidden], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        all_weights['b1'] = tf.get_variable('b1', shape=[self.n_hidden], initializer=tf.constant_initializer(0.0))\n",
    "        if tied == True:\n",
    "            all_weights['w2'] = tf.transpose(all_weights['w1'], name='w2')\n",
    "        else:\n",
    "            all_weights['w2'] = tf.get_variable('w2', shape=[self.n_hidden, self.n_input], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        all_weights['b2'] = tf.get_variable('b2', shape=[self.n_input], initializer=tf.constant_initializer(0.0))\n",
    "        return all_weights\n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer),\n",
    "                                  feed_dict = {self.x: X, self.keep_prob: self.dropout_probability})\n",
    "        return cost\n",
    "\n",
    "    def calc_total_cost(self, X):\n",
    "        return self.sess.run(self.cost, feed_dict = {self.x: X, self.keep_prob: 1.0})\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden, feed_dict = {self.x: X, self.keep_prob: 1.0})\n",
    "\n",
    "    def generate(self, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.x: X, self.keep_prob: 1.0})\n",
    "\n",
    "    def corrupt(self, X):\n",
    "        return self.sess.run(self.corrupted, feed_dict={self.x: X, self.keep_prob: self.dropout_probability})\n",
    "\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "\n",
    "    def getBiases(self):\n",
    "        return self.sess.run(self.weights['b1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data Loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training set and test set\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "X = newsgroups.data\n",
    "Y = newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"My point is that you set up your views as the only way to believe.  Saying \\nthat all eveil in this world is caused by atheism is ridiculous and \\ncounterproductive to dialogue in this newsgroups.  I see in your posts a \\nspirit of condemnation of the atheists in this newsgroup bacause they don'\\nt believe exactly as you do.  If you're here to try to convert the atheists \\nhere, you're failing miserably.  Who wants to be in position of constantly \\ndefending themselves agaist insulting attacks, like you seem to like to do?!\\nI'm sorry you're so blind that you didn't get the messgae in the quote, \\neveryone else has seemed to.\", \"\\nBy '8 grey level images' you mean 8 items of 1bit images?\\nIt does work(!), but it doesn't work if you have more than 1bit\\nin your screen and if the screen intensity is non-linear.\\n\\nWith 2 bit per pixel; there could be 1*c_1 + 4*c_2 timing,\\nthis gives 16 levels, but they are linear if screen intensity is\\nlinear.\\nWith 1*c_1 + 2*c_2 it works, but we have to find the best\\ncompinations -- there's 10 levels, but 16 choises; best 10 must be\\nchosen. Different compinations for the same level, varies a bit, but\\nthe levels keeps their order.\\n\\nReaders should verify what I wrote... :-)\"]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X[0:2])\n",
    "print(Y[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare two vectorizers\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting vectorizers to the training set\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrix into dense matrix\n",
    "X = X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training points:  3387\n"
     ]
    }
   ],
   "source": [
    "n_samples = Y.shape[0]\n",
    "print(\"Number of training points: \", n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X: 1315\n"
     ]
    }
   ],
   "source": [
    "dim_X = X.shape[1]\n",
    "print(\"Dimension of X: %d\" % dim_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(Y)\n",
    "print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. k-means clustering with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 2850.04896662\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 2796.13340262\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 2783.29582061\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 2780.18840161\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 2778.91232123\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 2778.44027739\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 2778.2270779\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 2778.10271669\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 2778.01092997\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 2777.95144568\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 2777.91952795\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 2777.90395194\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 2777.89105794\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 2777.88518344\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 2777.88288981\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 2777.88005134\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 2777.87866334\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 2777.87866334\n",
      "center shift 0.000000e+00 within tolerance 6.431008e-08\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 2858.53892953\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 2858.53892953\n",
      "center shift 0.000000e+00 within tolerance 6.431008e-08\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 2838.45446008\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 2785.23674413\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 2763.82051098\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 2756.81933393\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 2754.49187406\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 2753.40243627\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 2752.72185055\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 2752.25533242\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 2752.07403396\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 2751.91074019\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 2751.63420108\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 2751.26446317\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 2750.68652962\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 2749.99467521\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 2748.80847463\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 2747.5940044\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 2746.69686309\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 2745.88737339\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 2745.43686532\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 2745.05041218\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 2843.97668773\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 2809.53437197\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 2792.23905578\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 2783.89166575\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 2780.41087941\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 2778.22939258\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 2776.46300618\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 2774.74471067\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 2773.20078913\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 2772.30730011\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 2771.9356401\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 2771.7656649\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 2771.66255049\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 2771.60315056\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 2771.55333329\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 2771.52087335\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 2771.51346648\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 2771.50748559\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 2771.50351673\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 2771.49805585\n"
     ]
    }
   ],
   "source": [
    "n_clusters_set = [3, 4, 5, 6]\n",
    "names = []\n",
    "models = []\n",
    "results = []\n",
    "silhouette_scores = []\n",
    "mutual_scores = []\n",
    "for n_clusters in n_clusters_set:\n",
    "    # Add model name\n",
    "    names.append('KMeans_k=%d' % n_clusters)\n",
    "    # Call model\n",
    "    model = KMeans(n_clusters=n_clusters, n_init=1, max_iter=20, verbose=1)\n",
    "    # Fit the model\n",
    "    model.fit(X)\n",
    "    # Get cluster IDs\n",
    "    result = model.predict(X)\n",
    "    # Save model and result\n",
    "    models.append(model)\n",
    "    results.append(result)\n",
    "    # Calculate silhouette score\n",
    "    silhouette_scores.append(metrics.silhouette_score(X, result, metric = 'euclidean'))\n",
    "    # Calculate mutual_information\n",
    "    mutual_scores.append(metrics.adjusted_mutual_info_score(Y, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = pd.Series(silhouette_scores, index = names)\n",
    "mutual_scores = pd.Series(mutual_scores, index = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans_k=3    0.021667\n",
      "KMeans_k=4    0.004008\n",
      "KMeans_k=5    0.000668\n",
      "KMeans_k=6   -0.006071\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(silhouette_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans_k=3    0.147743\n",
      "KMeans_k=4    0.001344\n",
      "KMeans_k=5    0.152440\n",
      "KMeans_k=6    0.080803\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mutual_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 799   0   0]\n",
      " [  0 971   2   0]\n",
      " [  1 980   0   6]\n",
      " [  0 628   0   0]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(Y, results[1])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. k-means clustering with embedded vectors by denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "transfer_function = tf.nn.sigmoid # tf.nn.relu, tf.nn.softplus, tf.nn.sigmoid, tf.nn.tanh\n",
    "dropout_probability = 0.9\n",
    "training_epochs = 100\n",
    "batch_size = 32\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = MaskingNoiseAutoencoder(n_input=dim_X,\n",
    "                                      n_hidden=200,\n",
    "                                      transfer_function=transfer_function,\n",
    "                                      optimizer=tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                                      dropout_probability=dropout_probability,\n",
    "                                      tied_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_block_from_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index:(start_index + batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 \ttraining_cost= 520.729054904\n",
      "Epoch: 0002 \ttraining_cost= 36.889715257\n",
      "Epoch: 0003 \ttraining_cost= 24.029514526\n",
      "Epoch: 0004 \ttraining_cost= 19.470330553\n",
      "Epoch: 0005 \ttraining_cost= 17.388771023\n",
      "Epoch: 0006 \ttraining_cost= 16.012469309\n",
      "Epoch: 0007 \ttraining_cost= 15.232570589\n",
      "Epoch: 0008 \ttraining_cost= 14.729335518\n",
      "Epoch: 0009 \ttraining_cost= 14.487824892\n",
      "Epoch: 0010 \ttraining_cost= 14.110947101\n",
      "Epoch: 0011 \ttraining_cost= 13.885247031\n",
      "Epoch: 0012 \ttraining_cost= 13.883394181\n",
      "Epoch: 0013 \ttraining_cost= 13.668537096\n",
      "Epoch: 0014 \ttraining_cost= 13.661440836\n",
      "Epoch: 0015 \ttraining_cost= 13.603842434\n",
      "Epoch: 0016 \ttraining_cost= 13.438031909\n",
      "Epoch: 0017 \ttraining_cost= 13.475882076\n",
      "Epoch: 0018 \ttraining_cost= 13.477259647\n",
      "Epoch: 0019 \ttraining_cost= 13.359601499\n",
      "Epoch: 0020 \ttraining_cost= 13.422468728\n",
      "Epoch: 0021 \ttraining_cost= 13.296928476\n",
      "Epoch: 0022 \ttraining_cost= 13.284622792\n",
      "Epoch: 0023 \ttraining_cost= 13.268628274\n",
      "Epoch: 0024 \ttraining_cost= 13.235987602\n",
      "Epoch: 0025 \ttraining_cost= 13.262041162\n",
      "Epoch: 0026 \ttraining_cost= 13.256618449\n",
      "Epoch: 0027 \ttraining_cost= 13.239459254\n",
      "Epoch: 0028 \ttraining_cost= 13.088405910\n",
      "Epoch: 0029 \ttraining_cost= 13.117604997\n",
      "Epoch: 0030 \ttraining_cost= 13.118335968\n",
      "Epoch: 0031 \ttraining_cost= 13.101107070\n",
      "Epoch: 0032 \ttraining_cost= 13.025934932\n",
      "Epoch: 0033 \ttraining_cost= 13.089560974\n",
      "Epoch: 0034 \ttraining_cost= 13.078866288\n",
      "Epoch: 0035 \ttraining_cost= 13.017475328\n",
      "Epoch: 0036 \ttraining_cost= 12.886219359\n",
      "Epoch: 0037 \ttraining_cost= 13.072200634\n",
      "Epoch: 0038 \ttraining_cost= 12.984892934\n",
      "Epoch: 0039 \ttraining_cost= 12.978820990\n",
      "Epoch: 0040 \ttraining_cost= 12.924476527\n",
      "Epoch: 0041 \ttraining_cost= 12.969617025\n",
      "Epoch: 0042 \ttraining_cost= 13.041725053\n",
      "Epoch: 0043 \ttraining_cost= 12.944057306\n",
      "Epoch: 0044 \ttraining_cost= 13.051430174\n",
      "Epoch: 0045 \ttraining_cost= 12.929715360\n",
      "Epoch: 0046 \ttraining_cost= 13.001678305\n",
      "Epoch: 0047 \ttraining_cost= 13.015978020\n",
      "Epoch: 0048 \ttraining_cost= 12.899142477\n",
      "Epoch: 0049 \ttraining_cost= 12.908313969\n",
      "Epoch: 0050 \ttraining_cost= 12.842560013\n",
      "Epoch: 0051 \ttraining_cost= 12.887330255\n",
      "Epoch: 0052 \ttraining_cost= 12.818143689\n",
      "Epoch: 0053 \ttraining_cost= 12.854339023\n",
      "Epoch: 0054 \ttraining_cost= 12.908495804\n",
      "Epoch: 0055 \ttraining_cost= 12.813206932\n",
      "Epoch: 0056 \ttraining_cost= 12.882101883\n",
      "Epoch: 0057 \ttraining_cost= 12.777387080\n",
      "Epoch: 0058 \ttraining_cost= 12.894375211\n",
      "Epoch: 0059 \ttraining_cost= 12.800223032\n",
      "Epoch: 0060 \ttraining_cost= 12.789464211\n",
      "Epoch: 0061 \ttraining_cost= 12.798834919\n",
      "Epoch: 0062 \ttraining_cost= 12.901232890\n",
      "Epoch: 0063 \ttraining_cost= 12.692135041\n",
      "Epoch: 0064 \ttraining_cost= 12.681904579\n",
      "Epoch: 0065 \ttraining_cost= 12.787253610\n",
      "Epoch: 0066 \ttraining_cost= 12.625748559\n",
      "Epoch: 0067 \ttraining_cost= 12.774566110\n",
      "Epoch: 0068 \ttraining_cost= 12.693092258\n",
      "Epoch: 0069 \ttraining_cost= 12.761629071\n",
      "Epoch: 0070 \ttraining_cost= 12.761061960\n",
      "Epoch: 0071 \ttraining_cost= 12.704474387\n",
      "Epoch: 0072 \ttraining_cost= 12.640861851\n",
      "Epoch: 0073 \ttraining_cost= 12.655350700\n",
      "Epoch: 0074 \ttraining_cost= 12.663839578\n",
      "Epoch: 0075 \ttraining_cost= 12.672602529\n",
      "Epoch: 0076 \ttraining_cost= 12.440732440\n",
      "Epoch: 0077 \ttraining_cost= 12.544493998\n",
      "Epoch: 0078 \ttraining_cost= 12.536218400\n",
      "Epoch: 0079 \ttraining_cost= 12.541259964\n",
      "Epoch: 0080 \ttraining_cost= 12.455332015\n",
      "Epoch: 0081 \ttraining_cost= 12.379358337\n",
      "Epoch: 0082 \ttraining_cost= 12.501520644\n",
      "Epoch: 0083 \ttraining_cost= 12.412923393\n",
      "Epoch: 0084 \ttraining_cost= 12.454171716\n",
      "Epoch: 0085 \ttraining_cost= 12.479280529\n",
      "Epoch: 0086 \ttraining_cost= 12.339025560\n",
      "Epoch: 0087 \ttraining_cost= 12.451218242\n",
      "Epoch: 0088 \ttraining_cost= 12.417032481\n",
      "Epoch: 0089 \ttraining_cost= 12.279730681\n",
      "Epoch: 0090 \ttraining_cost= 12.375289732\n",
      "Epoch: 0091 \ttraining_cost= 12.334712094\n",
      "Epoch: 0092 \ttraining_cost= 12.242787247\n",
      "Epoch: 0093 \ttraining_cost= 12.189630518\n",
      "Epoch: 0094 \ttraining_cost= 12.194407190\n",
      "Epoch: 0095 \ttraining_cost= 12.151492718\n",
      "Epoch: 0096 \ttraining_cost= 12.189945209\n",
      "Epoch: 0097 \ttraining_cost= 12.122943969\n",
      "Epoch: 0098 \ttraining_cost= 12.180003272\n",
      "Epoch: 0099 \ttraining_cost= 12.073576079\n",
      "Epoch: 0100 \ttraining_cost= 12.019817234\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = get_random_block_from_data(X, batch_size)\n",
    "        \n",
    "        # Fit training using batch data\n",
    "        cost = autoencoder.partial_fit(batch_xs)\n",
    "        # Compute average loss\n",
    "        avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"\\ttraining_cost=\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_embedded = autoencoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 1402.47\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1289.32\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1252.49\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1245.06\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1242.96\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1241.65\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1241.16\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1241.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1240.95\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 1240.92\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 1240.92\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 1240.92\n",
      "center shift 0.000000e+00 within tolerance 2.750360e-07\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 1260.94\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1184.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1167.71\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1158.34\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1153.51\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1151.29\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1150.06\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1149.58\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1149.41\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 1149.26\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 1149.13\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 1149.08\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 1149.07\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 1149.06\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 1149.06\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 1149.06\n",
      "center shift 0.000000e+00 within tolerance 2.750360e-07\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 1292.31\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1170.64\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1128.88\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1115.6\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1081.01\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1062.87\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1057.05\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1054.15\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1052.13\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 1051.16\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 1050.79\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 1050.64\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 1050.57\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 1050.53\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 1050.49\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 1050.46\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 1050.4\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 1050.36\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 1050.34\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 1050.34\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 1050.34\n",
      "center shift 0.000000e+00 within tolerance 2.750360e-07\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 1159.55\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 1086.45\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 1053.95\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 1022.96\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 1010.93\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 1007.33\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 1006.12\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 1005.37\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 1005.01\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 1004.83\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 1004.79\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 1004.77\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 1004.76\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 1004.75\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 1004.74\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 1004.74\n",
      "center shift 0.000000e+00 within tolerance 2.750360e-07\n"
     ]
    }
   ],
   "source": [
    "n_clusters_set = [3, 4, 5, 6]\n",
    "names = []\n",
    "models = []\n",
    "results = []\n",
    "silhouette_scores = []\n",
    "mutual_scores = []\n",
    "for n_clusters in n_clusters_set:\n",
    "    # Add model name\n",
    "    names.append('KMeans_k=%d' % n_clusters)\n",
    "    # Call model\n",
    "    model = KMeans(n_clusters=n_clusters, n_init=1, max_iter=100, verbose=1)\n",
    "    # Fit the model\n",
    "    model.fit(X_embedded)\n",
    "    # Get cluster IDs\n",
    "    result = model.predict(X_embedded)\n",
    "    # Save model and result\n",
    "    models.append(model)\n",
    "    results.append(result)\n",
    "    # Calculate silhouette score\n",
    "    silhouette_scores.append(metrics.silhouette_score(X, result, metric = 'euclidean'))\n",
    "    # Calculate mutual_information\n",
    "    mutual_scores.append(metrics.adjusted_mutual_info_score(Y, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "silhouette_scores = pd.Series(silhouette_scores, index = names)\n",
    "mutual_scores = pd.Series(mutual_scores, index = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans_k=3    0.016379\n",
      "KMeans_k=4    0.003104\n",
      "KMeans_k=5   -0.005006\n",
      "KMeans_k=6   -0.036257\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(silhouette_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans_k=3    0.134068\n",
      "KMeans_k=4    0.200064\n",
      "KMeans_k=5    0.163654\n",
      "KMeans_k=6    0.146883\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mutual_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11 165   5 340 278]\n",
      " [142 143 485 181  22]\n",
      " [194 184  66 448  95]\n",
      " [  9 145   8 257 209]\n",
      " [  0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(Y, results[2])\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
