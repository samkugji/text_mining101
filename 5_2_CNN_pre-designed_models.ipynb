{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network (version 2)\n",
    "- 미리 만들어진 모델을 불러와서 학습을 해봅시다.\n",
    "- nets/kthvgg_slim.py 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pprint import pprint\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from mypackage.vgg_slim import vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "X_trn, Y_trn = mnist.train.images, mnist.train.labels\n",
    "X_val, Y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, Y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_trn[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trn = Y_trn.shape[0]\n",
    "num_val = Y_val.shape[0]\n",
    "num_test = Y_test.shape[0]\n",
    "\n",
    "print(\"Number of training points: \", num_trn)\n",
    "print(\"Number of validation points: \", num_val)\n",
    "print(\"Number of test points: \", num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_X = X_trn.shape[1]\n",
    "pixel_X = int(np.sqrt(dim_X)) # np.sqrt의 출력이 float32이므로, 이를 int 자료형으로 변경\n",
    "# dim_Y = Y_trn.shape[1]\n",
    "\n",
    "print(\"Dimension of X: %d (%d x %d)\" % (dim_X, pixel_X, pixel_X))\n",
    "# print(\"Dimension of Y: \", dim_Y)\n",
    "print(\"Dimension of Y: None.. Y is a array of integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trn = X_trn.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build the graph\n",
    "Tensorflow에서는 모델을 'graph'로 구현한다.\n",
    "\n",
    "### 1.1. Placeholder for inputs and outputs\n",
    "- Shape of the placeholder for inputs: [batch_size, input_dimension]\n",
    "- Shape of the placeholder for outputs: [batch_size]\n",
    "- Placeholder의 batch_size를 None으로 하면, placeholder에 들어가기 전에 batch size를 조절해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"Inputs\")\n",
    "Y = tf.placeholder(tf.int32, [None], name=\"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-designed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, end_points = vgg(inputs=X, num_classes=10)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print my end points\n",
    "pprint(end_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "### 2.1. Loss function\n",
    "- Classification 문제에서 제일 많이 사용하는 loss function은 **cross-entropy**\n",
    "\n",
    "두 가지 옵션이 있음.\n",
    "- tf.nn.softmax_cross_entropy_with_logits: Y가 one-hot encoded 되어 있을 때\n",
    "- tf.nn.sparse_softmax_cross_entropy_with_logits: Y가 class에 대한 index 값일 때)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Training operator\n",
    "- First, define the oprimizer. (**optimizer**)\n",
    "- And then, define training operator. (**train_op**)\n",
    "\n",
    "자주 사용하는 optimizer로는 다음과 같은 것들이 있음.\n",
    "- tf.train.GradientDescentOptimizer\n",
    "- tf.train.AdagradOptimizer\n",
    "- tf.train.MomentumOptimizer\n",
    "- **tf.train.AdamOptimizer** (많은 연구자들이 사용)\n",
    "\n",
    "자세한 사항은 [TensorFlow API_guides: Training](https://www.tensorflow.org/api_guides/python/train) 참조!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Predicting operator\n",
    "- correct_prediction: boolean (True or False)\n",
    "- accuracy: 먼저 correct_prediction을 float32로 변환 후에 배치 내 평균을 계산\n",
    "\n",
    "**tf.nn.in_top_k(x, y, k)**\n",
    "- tf.nn.in_top_k(x, y, k)는 prediction x의 상위 k개의 결과가 true label y를 포함하는지를 계산\n",
    "- 이에 대한 output은 boolean 으로 나오므로, 이를 0, 1로 바꿔주기 위해서 tf.cast를 이용하여 float32로 변환한 이후에 accuracy를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.nn.in_top_k(logits, Y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(correct_prediction))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(type(correct_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_prediction)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Run the session\n",
    "- 앞서 만든 graph, operator 등을 돌리는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch 인덱스 생성\n",
    "start_idx = range(0, num_trn, BATCH_SIZE)\n",
    "end_idx = range(BATCH_SIZE, num_trn + 1, BATCH_SIZE)\n",
    "for start, end in zip(start_idx, end_idx): print(start, '\\t', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_cost_list = []\n",
    "val_cost_list = []\n",
    "val_accuracy_list = []\n",
    "\n",
    "with tf.Session() as sess, tf.device(\"/cpu:0\"):\n",
    "    # Variable initialization\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Indices for constructing batches\n",
    "    start_idx = range(0, num_trn, BATCH_SIZE)\n",
    "    end_idx = range(BATCH_SIZE, num_trn + 1, BATCH_SIZE)\n",
    "    \n",
    "    NUM_BATCHES = len(start_idx)\n",
    "    \n",
    "    for epoch in range(0,NUM_EPOCHS):\n",
    "\n",
    "        # Set \"trn_cost\" as 0 before starting the epoch\n",
    "        trn_cost = 0\n",
    "        \n",
    "        # Training phase\n",
    "        for start, end in zip(start_idx, end_idx):\n",
    "\n",
    "            # Construct the input batch\n",
    "            batch_xs = X_trn[start:end]\n",
    "            batch_ys = Y_trn[start:end]\n",
    "            \n",
    "            # Calculate cost\n",
    "            tmp_cost, _ = sess.run([cost, train_op], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            trn_cost += tmp_cost\n",
    "        \n",
    "        trn_cost = trn_cost / NUM_BATCHES\n",
    "        trn_cost_list.append(trn_cost)\n",
    "        print(\"[{} epoch] training cost {:0.4f}\".format((epoch + 1), trn_cost))\n",
    "        \n",
    "        # Validation phase\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            val_cost, val_accuracy = sess.run([cost, accuracy], feed_dict={X: X_val, Y: Y_val})\n",
    "            val_cost_list.append(val_cost)\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "            print(\"\\t[{} epoch] validation accuracy {:0.4f}\".format((epoch + 1), val_accuracy))\n",
    "            \n",
    "    # Test phase\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: X_test, Y: Y_test})\n",
    "    print(\"\\n\")\n",
    "    print(\"Test accuracy: {:0.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Cost plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(50)\n",
    "plt.plot(x, trn_cost_list)\n",
    "plt.plot(x, test_cost_list)\n",
    "plt.title(\"cross entropy loss\")\n",
    "plt.legend([\"train loss\", \"test_loss\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cross entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(50)\n",
    "plt.plot(x, val_accuracy_list)\n",
    "plt.title(\"prediction accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
