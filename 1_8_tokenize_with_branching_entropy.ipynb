{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_APPEND_MYMODULES = True\n",
    "\n",
    "if USE_APPEND_MYMODULES is True:\n",
    "    sys.path.append('./mypackage/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_fname = \"./data/2016-10-28_article_all_normed.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_l_length = 6\n",
    "max_r_length = 5\n",
    "min_count = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corpus import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176597"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(corpus_fname, iter_sent=True)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "R = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176597/176597 [00:20<00:00, 8426.78it/s] \n"
     ]
    }
   ],
   "source": [
    "for num_sent, sent in enumerate(tqdm(corpus)):\n",
    "    \n",
    "    # if num_sent % 5000 == 0:\n",
    "        # sys.stdout.write(\"\\rinserting %d sents...\" % num_sent)\n",
    "    \n",
    "    for token in sent.split():\n",
    "        \n",
    "        if len(token)<2:\n",
    "            continue\n",
    "            \n",
    "        for e in range(2, min(max_l_length, len(token)) + 1):\n",
    "            subword_from = token[:e-1]\n",
    "            subword_to = token[:e]\n",
    "            L[subword_from][subword_to] += 1\n",
    "            \n",
    "        for b in range(2, min(max_r_length + 1, len(token))):\n",
    "            subword_from = token[:-b+1]\n",
    "            subword_to = token[-b:]\n",
    "            R[subword_from][subword_to] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
       "            {'트와이스가': 36,\n",
       "             '트와이스까': 1,\n",
       "             '트와이스는': 40,\n",
       "             '트와이스다': 1,\n",
       "             '트와이스와': 6,\n",
       "             '트와이스의': 34,\n",
       "             '트와이스코': 140,\n",
       "             '트와이스타': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.get(\"트와이스\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
       "            {'스가': 36,\n",
       "             '스까지': 1,\n",
       "             '스는': 40,\n",
       "             '스다': 1,\n",
       "             '스와': 6,\n",
       "             '스의': 34,\n",
       "             '스코스터': 140,\n",
       "             '스타로': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.get(\"트와이스\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessor Variety (Feng et ai., 2004)\n",
    "\n",
    "http://www.mitpressjournals.org/doi/abs/10.1162/089120104773633394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박근\t(50, 7)\n",
      "박근혜\t(41, 23)\n",
      "국방\t(66, 24)\n",
      "국방부\t(26, 13)\n",
      "국방부는\t(0, 0)\n",
      "국방장\t(9, 1)\n",
      "국방장관\t(8, 7)\n",
      "트와이\t(9, 1)\n",
      "트와이스\t(8, 8)\n"
     ]
    }
   ],
   "source": [
    "def get_accessor_variety(word):\n",
    "    \n",
    "    # av_l: ?-린이\n",
    "    # av_r: 어린-?\n",
    "    \n",
    "    av_l = 0 if not word in R else len(R[word])\n",
    "    av_r = 0 if not word in L else len(L[word])\n",
    "    return (av_l, av_r)\n",
    "\n",
    "\n",
    "for word in ['박근', '박근혜', '국방', '국방부', '국방부는', '국방장', '국방장관', '트와이', '트와이스']:\n",
    "    av = get_accessor_variety(word)\n",
    "    print('%s\\t(%d, %d)' % (word, av[0], av[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branching Entropy (Jin & Tanaka, 2006)\n",
    "http://dl.acm.org/citation.cfm?id=1273129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박근\t(0.594, 0.082)\n",
      "박근혜\t(2.707, 2.305)\n",
      "국방\t(2.580, 1.097)\n",
      "국방부\t(1.776, 1.601)\n",
      "국방부는\t(0.000, 0.000)\n",
      "국방장\t(1.809, -0.000)\n",
      "국방장관\t(1.631, 1.575)\n",
      "트와이\t(1.142, -0.000)\n",
      "트와이스\t(1.313, 1.313)\n"
     ]
    }
   ],
   "source": [
    "def get_branching_entropy(word):\n",
    "    \n",
    "    def entropy(extensions):\n",
    "        '''extensions: dict[str]: int\n",
    "        '''\n",
    "        sum_ = sum(extensions.values())\n",
    "        if sum_ == 0:\n",
    "            return 0\n",
    "        \n",
    "        entropy = 0\n",
    "        for v in extensions.values():\n",
    "            if v == 0: continue\n",
    "            prob = v / sum_\n",
    "            entropy += (prob * np.log(prob)) # important\n",
    "        return -1 * entropy\n",
    "\n",
    "    # be_l: ?-린이\n",
    "    # be_r: 어린-?\n",
    "    \n",
    "    be_l = 0 if not word in R else entropy(R[word])\n",
    "    be_r = 0 if not word in L else entropy(L[word])    \n",
    "    return (be_l, be_r)\n",
    "\n",
    "\n",
    "for word in ['박근', '박근혜', '국방', '국방부', '국방부는', '국방장', '국방장관', '트와이', '트와이스']:\n",
    "    be = get_branching_entropy(word)\n",
    "    print('%s\\t(%.3f, %.3f)' % (word, be[0], be[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
